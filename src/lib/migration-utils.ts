import { supabase, uploadFileToStorage, getBucketForFileType, generateUniqueFileName } from './supabase'
import { getAllWorkRecords, WorkRecordData } from './work-records'

// Base64 ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
export const base64ToFile = (base64Data: string, fileName: string, mimeType: string): File => {
  try {
    // base64 ë°ì´í„°ì—ì„œ data: prefix ì œê±°
    const cleanBase64 = base64Data.replace(/^data:[^;]+;base64,/, '')
    
    console.log(`ğŸ”„ Base64 â†’ File ë³€í™˜: ${fileName}`)
    console.log(`ğŸ“Š Base64 ê¸¸ì´: ${cleanBase64.length} ë¬¸ì`)
    
    const byteCharacters = atob(cleanBase64)
    const byteNumbers = new Array(byteCharacters.length)
    
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i)
    }
    
    const byteArray = new Uint8Array(byteNumbers)
    const blob = new Blob([byteArray], { type: mimeType })
    const file = new File([blob], fileName, { type: mimeType })
    
    console.log(`âœ… íŒŒì¼ ë³€í™˜ ì™„ë£Œ: ${file.size} bytes`)
    
    return file
  } catch (error) {
    console.error('âŒ Base64 â†’ File ë³€í™˜ ì‹¤íŒ¨:', error)
    throw new Error(`Base64 ë³€í™˜ ì‹¤íŒ¨: ${fileName}`)
  }
}

// ë‹¨ì¼ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateFileToStorage = async (
  fileData: any,
  workRecordId: number,
  category: string
): Promise<{ storagePath: string, storageUrl: string, bucketName: string } | null> => {
  try {
    console.log(`ğŸ” íŒŒì¼ ë°ì´í„° êµ¬ì¡° í™•ì¸:`, {
      hasData: !!fileData.data,
      hasName: !!fileData.name,
      hasType: !!fileData.type,
      dataType: typeof fileData.data,
      dataLength: fileData.data?.length || 0,
      fileName: fileData.name,
      fileType: fileData.type
    })
    
    if (!fileData.data || !fileData.name) {
      console.log('âŒ íŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤:', fileData)
      return null
    }

    // File ê°ì²´ ìƒì„±
    const file = base64ToFile(fileData.data, fileData.name, fileData.type || 'application/octet-stream')
    
    // ë²„í‚· ë° íŒŒì¼ëª… ê²°ì •
    const bucketName = getBucketForFileType(file.type, category)
    const uniqueFileName = generateUniqueFileName(file.name, workRecordId)
    
    // Storageì— ì—…ë¡œë“œ
    const uploadResult = await uploadFileToStorage(file, bucketName, uniqueFileName)
    
    // íŒŒì¼ ë©”íƒ€ë°ì´í„° DB ì €ì¥
    const { error: metadataError } = await supabase
      .from('file_metadata')
      .insert({
        work_record_id: workRecordId,
        file_name: file.name,
        file_size: file.size,
        file_type: file.type,
        category: category,
        storage_path: uploadResult.path,
        storage_url: uploadResult.url,
        bucket_name: bucketName,
        description: fileData.description || ''
      })

    if (metadataError) {
      console.error('íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì˜¤ë¥˜:', metadataError)
      throw metadataError
    }

    console.log(`âœ… íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${file.name} â†’ ${bucketName}/${uniqueFileName}`)
    
    return {
      storagePath: uploadResult.path,
      storageUrl: uploadResult.url,
      bucketName: bucketName
    }
  } catch (error) {
    console.error('íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜:', error)
    return null
  }
}

// ì‘ì—… ê¸°ë¡ì˜ ëª¨ë“  íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateWorkRecordFiles = async (workRecord: WorkRecordData): Promise<boolean> => {
  try {
    console.log(`ğŸ”„ ì‘ì—… ê¸°ë¡ ${workRecord.id} íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...`)
    
    if (!workRecord.remappingWorks || workRecord.remappingWorks.length === 0) {
      console.log('ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
      return true
    }

    const firstWork = workRecord.remappingWorks[0] as any
    let migratedFiles: any[] = []
    let migrationCount = 0

    // ECU íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.files) {
      const ecuCategories = ['original', 'read', 'modified', 'vr', 'stage1', 'stage2', 'stage3']
      
      for (const category of ecuCategories) {
        const fileData = (firstWork.files as any)[category]
        if (fileData && fileData.file) {
          const result = await migrateFileToStorage(fileData.file, workRecord.id, `ecu_${category}`)
          if (result) {
            migratedFiles.push({
              category: `ecu_${category}`,
              originalData: fileData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ACU íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.acu && firstWork.acu.files) {
      const acuCategories = ['acuOriginal', 'acuStage1', 'acuStage2', 'acuStage3']
      
      for (const category of acuCategories) {
        const fileData = (firstWork.acu.files as any)[category]
        if (fileData && fileData.file) {
          const result = await migrateFileToStorage(fileData.file, workRecord.id, category)
          if (result) {
            migratedFiles.push({
              category: category,
              originalData: fileData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ë¯¸ë””ì–´ íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.media) {
      const mediaCategories = ['before', 'after']
      
      for (const category of mediaCategories) {
        const mediaData = (firstWork.media as any)[category]
        if (mediaData) {
          const result = await migrateFileToStorage(mediaData, workRecord.id, `media_${category}`)
          if (result) {
            migratedFiles.push({
              category: `media_${category}`,
              originalData: mediaData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ì¶”ê°€ ë¯¸ë””ì–´ íŒŒì¼ë“¤ (mediaFile1~5)
    if (firstWork.files) {
      for (let i = 1; i <= 5; i++) {
        const mediaFile = (firstWork.files as any)[`mediaFile${i}`]
        if (mediaFile && mediaFile.file) {
          const result = await migrateFileToStorage(mediaFile.file, workRecord.id, `media_file_${i}`)
          if (result) {
            migratedFiles.push({
              category: `media_file_${i}`,
              originalData: mediaFile,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    console.log(`âœ… ì‘ì—… ê¸°ë¡ ${workRecord.id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${migrationCount}ê°œ íŒŒì¼`)
    return true

  } catch (error) {
    console.error(`âŒ ì‘ì—… ê¸°ë¡ ${workRecord.id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:`, error)
    return false
  }
}

// ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateAllFilesToStorage = async (
  onProgress?: (current: number, total: number, recordId: number) => void
): Promise<{ success: number, failed: number, total: number }> => {
  try {
    console.log('ğŸš€ ì „ì²´ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...')
    
    // ëª¨ë“  ì‘ì—… ê¸°ë¡ ì¡°íšŒ (íŒŒì¼ í¬í•¨)
    const workRecords = await getAllWorkRecords()
    const total = workRecords.length
    let success = 0
    let failed = 0

    console.log(`ğŸ“Š ì´ ${total}ê°œ ì‘ì—… ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì •`)

    for (let i = 0; i < workRecords.length; i++) {
      const record = workRecords[i]
      
      // ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
      if (onProgress) {
        onProgress(i + 1, total, record.id)
      }

      // ê°œë³„ ì‘ì—… ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜
      const result = await migrateWorkRecordFiles(record)
      if (result) {
        success++
      } else {
        failed++
      }

      // ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
      await new Promise(resolve => setTimeout(resolve, 100))
    }

    console.log(`ğŸ‰ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ! ì„±ê³µ: ${success}, ì‹¤íŒ¨: ${failed}`)
    
    return { success, failed, total }

  } catch (error) {
    console.error('âŒ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:', error)
    return { success: 0, failed: 1, total: 1 }
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
export const checkMigrationStatus = async (): Promise<{
  totalRecords: number,
  migratedRecords: number,
  pendingRecords: number,
  migrationProgress: number
}> => {
  try {
    // ì „ì²´ ì‘ì—… ê¸°ë¡ ìˆ˜
    const { count: totalRecords } = await supabase
      .from('work_records')
      .select('*', { count: 'exact', head: true })

    // ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ê¸°ë¡ ìˆ˜ í™•ì¸
    const { data: migratedData, error: migratedError } = await supabase
      .from('file_metadata')
      .select('work_record_id')
    
    if (migratedError) {
      console.error('ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜:', migratedError)
    }
    
    // ê³ ìœ í•œ work_record_id ê°œìˆ˜ ê³„ì‚°
    const uniqueWorkRecordIds = new Set(migratedData?.map(item => item.work_record_id) || [])
    const migratedRecords = uniqueWorkRecordIds.size

    const pendingRecords = (totalRecords || 0) - migratedRecords
    const migrationProgress = totalRecords ? (migratedRecords / totalRecords) * 100 : 0

    return {
      totalRecords: totalRecords || 0,
      migratedRecords: migratedRecords,
      pendingRecords: Math.max(0, pendingRecords),
      migrationProgress: Math.round(migrationProgress)
    }
  } catch (error) {
    console.error('ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error)
    return {
      totalRecords: 0,
      migratedRecords: 0,
      pendingRecords: 0,
      migrationProgress: 0
    }
  }
} 
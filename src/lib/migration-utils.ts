import { supabase, uploadFileToStorage, getBucketForFileType, generateUniqueFileName } from './supabase'
import { Tables } from './database.types'

type WorkRecordData = Tables<'work_records'>

// ë§ˆì´ê·¸ë ˆì´ì…˜ìš© ì‘ì—… ê¸°ë¡ ì¡°íšŒ (ëª¨ë“  ë°ì´í„° í¬í•¨)
const getAllWorkRecordsForMigration = async (): Promise<WorkRecordData[]> => {
  const { data, error } = await supabase
    .from('work_records')
    .select('*')
    .order('created_at', { ascending: false })
  
  if (error) {
    console.error('Error fetching work records for migration:', error)
    throw error
  }
  
  return data
}

// Base64 ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
export const base64ToFile = (base64Data: string, fileName: string, mimeType: string): File => {
  try {
    // base64 ë°ì´í„°ì—ì„œ data: prefix ì œê±°
    const cleanBase64 = base64Data.replace(/^data:[^;]+;base64,/, '')
    
    console.log(`ğŸ”„ Base64 â†’ File ë³€í™˜: ${fileName}`)
    console.log(`ğŸ“Š Base64 ê¸¸ì´: ${cleanBase64.length} ë¬¸ì`)
    
    const byteCharacters = atob(cleanBase64)
    const byteNumbers = new Array(byteCharacters.length)
    
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i)
    }
    
    const byteArray = new Uint8Array(byteNumbers)
    const blob = new Blob([byteArray], { type: mimeType })
    const file = new File([blob], fileName, { type: mimeType })
    
    console.log(`âœ… íŒŒì¼ ë³€í™˜ ì™„ë£Œ: ${file.size} bytes`)
    
    return file
  } catch (error) {
    console.error('âŒ Base64 â†’ File ë³€í™˜ ì‹¤íŒ¨:', error)
    throw new Error(`Base64 ë³€í™˜ ì‹¤íŒ¨: ${fileName}`)
  }
}

// ë‹¨ì¼ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateFileToStorage = async (
  fileData: any,
  workRecordId: number,
  category: string
): Promise<{ storagePath: string, storageUrl: string, bucketName: string } | null> => {
  try {
    console.log(`ğŸ” íŒŒì¼ ë°ì´í„° êµ¬ì¡° í™•ì¸:`, {
      hasData: !!fileData.data,
      hasName: !!fileData.name,
      hasType: !!fileData.type,
      dataType: typeof fileData.data,
      dataLength: fileData.data?.length || 0,
      fileName: fileData.name,
      fileType: fileData.type
    })
    
    if (!fileData.data || !fileData.name) {
      console.log('âŒ íŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤:', fileData)
      return null
    }

    // File ê°ì²´ ìƒì„±
    const file = base64ToFile(fileData.data, fileData.name, fileData.type || 'application/octet-stream')
    
    // ë²„í‚· ë° íŒŒì¼ëª… ê²°ì •
    const bucketName = getBucketForFileType(file.type, category)
    const uniqueFileName = generateUniqueFileName(file.name, workRecordId)
    
    // Storageì— ì—…ë¡œë“œ
    const uploadResult = await uploadFileToStorage(file, bucketName, uniqueFileName)
    
    // íŒŒì¼ ë©”íƒ€ë°ì´í„° DB ì €ì¥
    const { error: metadataError } = await supabase
      .from('file_metadata')
      .insert({
        work_record_id: workRecordId,
        file_name: file.name,
        file_size: file.size,
        file_type: file.type,
        category: category,
        storage_path: uploadResult.path,
        storage_url: uploadResult.url,
        bucket_name: bucketName,
        description: fileData.description || ''
      })

    if (metadataError) {
      console.error('íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì˜¤ë¥˜:', metadataError)
      throw metadataError
    }

    console.log(`âœ… íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${file.name} â†’ ${bucketName}/${uniqueFileName}`)
    
    return {
      storagePath: uploadResult.path,
      storageUrl: uploadResult.url,
      bucketName: bucketName
    }
  } catch (error) {
    console.error('íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜:', error)
    return null
  }
}

// ì‘ì—… ê¸°ë¡ì˜ ëª¨ë“  íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateWorkRecordFiles = async (workRecord: WorkRecordData): Promise<boolean> => {
  try {
    console.log(`ğŸ”„ ì‘ì—… ê¸°ë¡ ${workRecord.id} íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...`)
    
    // remapping_worksëŠ” Json íƒ€ì…ì´ë¯€ë¡œ ë°°ì—´ë¡œ íŒŒì‹±
    const remappingWorks = Array.isArray(workRecord.remapping_works) 
      ? workRecord.remapping_works 
      : (workRecord.remapping_works ? [workRecord.remapping_works] : [])
    
    if (!remappingWorks || remappingWorks.length === 0) {
      console.log('ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
      return true
    }

    const firstWork = remappingWorks[0] as any
    let migratedFiles: any[] = []
    let migrationCount = 0

    // ECU íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.files) {
      const ecuCategories = ['original', 'read', 'modified', 'vr', 'stage1', 'stage2', 'stage3']
      
      for (const category of ecuCategories) {
        const fileData = (firstWork.files as any)[category]
        if (fileData && fileData.file) {
          const result = await migrateFileToStorage(fileData.file, workRecord.id, `ecu_${category}`)
          if (result) {
            migratedFiles.push({
              category: `ecu_${category}`,
              originalData: fileData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ACU íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.acu && firstWork.acu.files) {
      const acuCategories = ['acuOriginal', 'acuStage1', 'acuStage2', 'acuStage3']
      
      for (const category of acuCategories) {
        const fileData = (firstWork.acu.files as any)[category]
        if (fileData && fileData.file) {
          const result = await migrateFileToStorage(fileData.file, workRecord.id, category)
          if (result) {
            migratedFiles.push({
              category: category,
              originalData: fileData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ë¯¸ë””ì–´ íŒŒì¼ë“¤ ë§ˆì´ê·¸ë ˆì´ì…˜
    if (firstWork.media) {
      const mediaCategories = ['before', 'after']
      
      for (const category of mediaCategories) {
        const mediaData = (firstWork.media as any)[category]
        if (mediaData) {
          const result = await migrateFileToStorage(mediaData, workRecord.id, `media_${category}`)
          if (result) {
            migratedFiles.push({
              category: `media_${category}`,
              originalData: mediaData,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    // ì¶”ê°€ ë¯¸ë””ì–´ íŒŒì¼ë“¤ (mediaFile1~5)
    if (firstWork.files) {
      for (let i = 1; i <= 5; i++) {
        const mediaFile = (firstWork.files as any)[`mediaFile${i}`]
        if (mediaFile && mediaFile.file) {
          const result = await migrateFileToStorage(mediaFile.file, workRecord.id, `media_file_${i}`)
          if (result) {
            migratedFiles.push({
              category: `media_file_${i}`,
              originalData: mediaFile,
              storageInfo: result
            })
            migrationCount++
          }
        }
      }
    }

    console.log(`âœ… ì‘ì—… ê¸°ë¡ ${workRecord.id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${migrationCount}ê°œ íŒŒì¼`)
    return true

  } catch (error) {
    console.error(`âŒ ì‘ì—… ê¸°ë¡ ${workRecord.id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:`, error)
    return false
  }
}

// ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
export const migrateAllFilesToStorage = async (
  onProgress?: (current: number, total: number, recordId: number) => void
): Promise<{ success: number, failed: number, total: number }> => {
  try {
    console.log('ğŸš€ ì „ì²´ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...')
    
    // ëª¨ë“  ì‘ì—… ê¸°ë¡ ì¡°íšŒ (íŒŒì¼ í¬í•¨)
    const workRecords = await getAllWorkRecordsForMigration()
    const total = workRecords.length
    let success = 0
    let failed = 0

    console.log(`ğŸ“Š ì´ ${total}ê°œ ì‘ì—… ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì •`)

    for (let i = 0; i < workRecords.length; i++) {
      const record = workRecords[i]
      
      // ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
      if (onProgress) {
        onProgress(i + 1, total, record.id)
      }

      // ê°œë³„ ì‘ì—… ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜
      const result = await migrateWorkRecordFiles(record)
      if (result) {
        success++
      } else {
        failed++
      }

      // ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
      await new Promise(resolve => setTimeout(resolve, 100))
    }

    console.log(`ğŸ‰ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ! ì„±ê³µ: ${success}, ì‹¤íŒ¨: ${failed}`)
    
    return { success, failed, total }

  } catch (error) {
    console.error('âŒ ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:', error)
    return { success: 0, failed: 1, total: 1 }
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
export const checkMigrationStatus = async (): Promise<{
  totalRecords: number,
  migratedRecords: number,
  pendingRecords: number,
  migrationProgress: number
}> => {
  try {
    // ì „ì²´ ì‘ì—… ê¸°ë¡ ìˆ˜
    const { count: totalRecords } = await supabase
      .from('work_records')
      .select('*', { count: 'exact', head: true })

    // ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ê¸°ë¡ ìˆ˜ í™•ì¸
    const { data: migratedData, error: migratedError } = await supabase
      .from('file_metadata')
      .select('work_record_id')
    
    if (migratedError) {
      console.error('ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜:', migratedError)
    }
    
    // ê³ ìœ í•œ work_record_id ê°œìˆ˜ ê³„ì‚°
    const uniqueWorkRecordIds = new Set(migratedData?.map(item => item.work_record_id) || [])
    const migratedRecords = uniqueWorkRecordIds.size

    const pendingRecords = (totalRecords || 0) - migratedRecords
    const migrationProgress = totalRecords ? (migratedRecords / totalRecords) * 100 : 0

    return {
      totalRecords: totalRecords || 0,
      migratedRecords: migratedRecords,
      pendingRecords: Math.max(0, pendingRecords),
      migrationProgress: Math.round(migrationProgress)
    }
  } catch (error) {
    console.error('ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error)
    return {
      totalRecords: 0,
      migratedRecords: 0,
      pendingRecords: 0,
      migrationProgress: 0
    }
  }
}

// ë°ì´í„° êµ¬ì¡° ë¶„ì„ì„ ìœ„í•œ ë””ë²„ê¹… í•¨ìˆ˜
export const analyzeWorkRecordData = async (workRecordId?: number): Promise<void> => {
  try {
    console.log('ğŸ” ì‘ì—… ê¸°ë¡ ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘...')
    
    // íŠ¹ì • IDê°€ ì£¼ì–´ì§€ë©´ í•´ë‹¹ ê¸°ë¡ë§Œ, ì•„ë‹ˆë©´ ëª¨ë“  ê¸°ë¡ ì¡°íšŒ
    const query = workRecordId 
      ? supabase.from('work_records').select('*').eq('id', workRecordId)
      : supabase.from('work_records').select('*').limit(5)
    
    const { data: workRecords, error } = await query
    
    if (error) {
      console.error('âŒ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜:', error)
      return
    }
    
    if (!workRecords || workRecords.length === 0) {
      console.log('âŒ ì¡°íšŒëœ ì‘ì—… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.')
      return
    }
    
    console.log(`ğŸ“Š ì´ ${workRecords.length}ê°œ ì‘ì—… ê¸°ë¡ ë¶„ì„`)
    
    for (const record of workRecords) {
      console.log(`\nğŸ” ì‘ì—… ê¸°ë¡ ID: ${record.id}`)
      console.log(`ğŸ“… ì‘ì—… ë‚ ì§œ: ${record.work_date}`)
      console.log(`ğŸ’° ê°€ê²©: ${record.total_price}`)
      
      // remapping_works êµ¬ì¡° ë¶„ì„
      if (record.remapping_works) {
        console.log('ğŸ“‹ remapping_works êµ¬ì¡°:')
        console.log('  - íƒ€ì…:', typeof record.remapping_works)
        console.log('  - ë°°ì—´ ì—¬ë¶€:', Array.isArray(record.remapping_works))
        
        // Json íƒ€ì…ì„ ë°°ì—´ë¡œ íŒŒì‹±
        const remappingWorks = Array.isArray(record.remapping_works) 
          ? record.remapping_works 
          : (record.remapping_works ? [record.remapping_works] : [])
        
        if (remappingWorks && remappingWorks.length > 0) {
          const firstWork = remappingWorks[0] as any
          console.log('  - ì²« ë²ˆì§¸ ì‘ì—… êµ¬ì¡°:')
          console.log('    - files:', !!firstWork.files)
          console.log('    - acu:', !!firstWork.acu)
          console.log('    - media:', !!firstWork.media)
          
          if (firstWork.files) {
            console.log('    - files ë‚´ìš©:', Object.keys(firstWork.files))
            
            // ê° íŒŒì¼ ì¹´í…Œê³ ë¦¬ í™•ì¸
            const categories = ['original', 'read', 'modified', 'vr', 'stage1', 'stage2', 'stage3']
            for (const category of categories) {
              const fileData = firstWork.files[category]
              if (fileData) {
                console.log(`      - ${category}:`, {
                  hasFile: !!fileData.file,
                  hasData: !!(fileData.file && fileData.file.data),
                  hasName: !!(fileData.file && fileData.file.name),
                  dataLength: fileData.file?.data?.length || 0
                })
              }
            }
            
            // ë¯¸ë””ì–´ íŒŒì¼ë“¤ í™•ì¸
            for (let i = 1; i <= 5; i++) {
              const mediaFile = firstWork.files[`mediaFile${i}`]
              if (mediaFile) {
                console.log(`      - mediaFile${i}:`, {
                  hasFile: !!mediaFile.file,
                  hasData: !!(mediaFile.file && mediaFile.file.data),
                  hasName: !!(mediaFile.file && mediaFile.file.name),
                  dataLength: mediaFile.file?.data?.length || 0
                })
              }
            }
          }
          
          if (firstWork.acu && firstWork.acu.files) {
            console.log('    - ACU files ë‚´ìš©:', Object.keys(firstWork.acu.files))
          }
          
          if (firstWork.media) {
            console.log('    - media ë‚´ìš©:', Object.keys(firstWork.media))
          }
        }
      } else {
        console.log('âŒ remapping_worksê°€ ì—†ìŠµë‹ˆë‹¤.')
      }
      
      // files í•„ë“œ ì§ì ‘ í™•ì¸
      if (record.files) {
        console.log('ğŸ“ ì§ì ‘ files í•„ë“œ:', typeof record.files)
      }
    }
    
  } catch (error) {
    console.error('âŒ ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜:', error)
  }
}

// íŠ¹ì • work_recordì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ ë° ë¶„ì„
export const analyzeSpecificWorkRecord = async (workRecordId: number): Promise<void> => {
  try {
    console.log(`ğŸ” ì‘ì—… ê¸°ë¡ ID ${workRecordId} ìƒì„¸ ë¶„ì„ ì‹œì‘...`)
    
    // 1. ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
    const { data: record, error } = await supabase
      .from('work_records')
      .select('*')
      .eq('id', workRecordId)
      .single()
    
    if (error) {
      console.error(`âŒ ì‘ì—… ê¸°ë¡ ${workRecordId} ì¡°íšŒ ì˜¤ë¥˜:`, error)
      return
    }
    
    if (!record) {
      console.log(`âŒ ì‘ì—… ê¸°ë¡ ${workRecordId}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.`)
      return
    }
    
    console.log(`âœ… ì‘ì—… ê¸°ë¡ ${workRecordId} ê¸°ë³¸ ì •ë³´:`)
    console.log('  - ID:', record.id)
    console.log('  - ê³ ê° ID:', record.customer_id)
    console.log('  - ì¥ë¹„ ID:', record.equipment_id)
    console.log('  - ì‘ì—… ë‚ ì§œ:', record.work_date)
    console.log('  - ì‘ì—… ìœ í˜•:', record.work_type)
    console.log('  - ì´ ê°€ê²©:', record.total_price)
    console.log('  - ìƒíƒœ:', record.status)
    console.log('  - ECU ë©”ì´ì»¤:', record.ecu_maker)
    console.log('  - ECU ëª¨ë¸:', record.ecu_model)
    console.log('  - ACU ì œì¡°ì‚¬:', record.acu_manufacturer)
    console.log('  - ACU ëª¨ë¸:', record.acu_model)
    console.log('  - ì—°ê²° ë°©ë²•:', record.connection_method)
    
    // 2. remapping_works ë¶„ì„
    if (record.remapping_works) {
      console.log('ğŸ“‹ remapping_works ë¶„ì„:')
      console.log('  - íƒ€ì…:', typeof record.remapping_works)
      console.log('  - ì›ë³¸ ë°ì´í„°:', record.remapping_works)
      
      try {
        const parsedWorks = typeof record.remapping_works === 'string' 
          ? JSON.parse(record.remapping_works)
          : record.remapping_works
        
        console.log('  - íŒŒì‹±ëœ ë°ì´í„°:', parsedWorks)
        console.log('  - ë°°ì—´ ì—¬ë¶€:', Array.isArray(parsedWorks))
        
        if (Array.isArray(parsedWorks) && parsedWorks.length > 0) {
          const firstWork = parsedWorks[0]
          console.log('  - ì²« ë²ˆì§¸ ì‘ì—…:', firstWork)
          
          if (firstWork.files) {
            console.log('  - íŒŒì¼ ë°ì´í„° ì¡´ì¬:', !!firstWork.files)
            console.log('  - íŒŒì¼ ë°ì´í„° íƒ€ì…:', typeof firstWork.files)
            console.log('  - íŒŒì¼ ë°ì´í„°:', firstWork.files)
          }
        }
      } catch (parseError) {
        console.error('  - JSON íŒŒì‹± ì˜¤ë¥˜:', parseError)
      }
    } else {
      console.log('âŒ remapping_worksê°€ ì—†ìŠµë‹ˆë‹¤.')
    }
    
    // 3. files í•„ë“œ ë¶„ì„
    if (record.files) {
      console.log('ğŸ“ files í•„ë“œ ë¶„ì„:')
      console.log('  - íƒ€ì…:', typeof record.files)
      console.log('  - ì›ë³¸ ë°ì´í„°:', record.files)
      
      try {
        const parsedFiles = typeof record.files === 'string' 
          ? JSON.parse(record.files)
          : record.files
        
        console.log('  - íŒŒì‹±ëœ íŒŒì¼ ë°ì´í„°:', parsedFiles)
        
        if (Array.isArray(parsedFiles)) {
          console.log(`  - íŒŒì¼ ê°œìˆ˜: ${parsedFiles.length}ê°œ`)
          parsedFiles.forEach((file, index) => {
            console.log(`    íŒŒì¼ ${index + 1}:`, {
              name: file.name,
              size: file.size,
              type: file.type,
              category: file.category,
              hasData: !!file.data,
              dataLength: file.data?.length || 0
            })
          })
        }
      } catch (parseError) {
        console.error('  - íŒŒì¼ JSON íŒŒì‹± ì˜¤ë¥˜:', parseError)
      }
    } else {
      console.log('âŒ files í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.')
    }
    
    // 4. ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
    const { data: migratedFiles, error: migrationError } = await supabase
      .from('file_metadata')
      .select('*')
      .eq('work_record_id', workRecordId)
    
    if (migrationError) {
      console.error('  - ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜:', migrationError)
    } else {
      console.log(`ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ: ${migratedFiles?.length || 0}ê°œ íŒŒì¼ì´ Storageì— ì €ì¥ë¨`)
      if (migratedFiles && migratedFiles.length > 0) {
        migratedFiles.forEach((file, index) => {
          console.log(`  ë§ˆì´ê·¸ë ˆì´ì…˜ëœ íŒŒì¼ ${index + 1}:`, {
            fileName: file.file_name,
            category: file.category,
            bucketName: file.bucket_name,
            storageUrl: file.storage_url
          })
        })
      }
    }
    
  } catch (error) {
    console.error(`âŒ ì‘ì—… ê¸°ë¡ ${workRecordId} ë¶„ì„ ì˜¤ë¥˜:`, error)
  }
}

// ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½
export const getDatabaseSummary = async (): Promise<void> => {
  try {
    console.log('ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½ ì‹œì‘...')
    
    // 1. ì „ì²´ ì‘ì—… ê¸°ë¡ ìˆ˜
    const { count: totalRecords } = await supabase
      .from('work_records')
      .select('*', { count: 'exact', head: true })
    
    // 2. remapping_worksê°€ ìˆëŠ” ê¸°ë¡ ìˆ˜
    const { count: recordsWithRemapping } = await supabase
      .from('work_records')
      .select('*', { count: 'exact', head: true })
      .not('remapping_works', 'is', null)
    
    // 3. filesê°€ ìˆëŠ” ê¸°ë¡ ìˆ˜
    const { count: recordsWithFiles } = await supabase
      .from('work_records')
      .select('*', { count: 'exact', head: true })
      .not('files', 'is', null)
    
    // 4. ë§ˆì´ê·¸ë ˆì´ì…˜ëœ íŒŒì¼ ìˆ˜
    const { count: migratedFiles } = await supabase
      .from('file_metadata')
      .select('*', { count: 'exact', head: true })
    
    // 5. ê³ ìœ í•œ work_record_id ìˆ˜ (ë§ˆì´ê·¸ë ˆì´ì…˜ëœ)
    const { data: uniqueWorkRecords } = await supabase
      .from('file_metadata')
      .select('work_record_id')
    
    const uniqueCount = new Set(uniqueWorkRecords?.map(r => r.work_record_id) || []).size
    
    console.log('ğŸ“ˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½:')
    console.log(`  - ì „ì²´ ì‘ì—… ê¸°ë¡: ${totalRecords || 0}ê°œ`)
    console.log(`  - remapping_works ìˆëŠ” ê¸°ë¡: ${recordsWithRemapping || 0}ê°œ`)
    console.log(`  - files í•„ë“œ ìˆëŠ” ê¸°ë¡: ${recordsWithFiles || 0}ê°œ`)
    console.log(`  - ë§ˆì´ê·¸ë ˆì´ì…˜ëœ íŒŒì¼: ${migratedFiles || 0}ê°œ`)
    console.log(`  - ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ì‘ì—… ê¸°ë¡: ${uniqueCount}ê°œ`)
    console.log(`  - ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰ë¥ : ${totalRecords ? (uniqueCount / totalRecords * 100).toFixed(1) : 0}%`)
    
    // 6. ìµœê·¼ 5ê°œ ì‘ì—… ê¸°ë¡ ID í‘œì‹œ
    const { data: recentRecords } = await supabase
      .from('work_records')
      .select('id, work_date, ecu_maker, acu_manufacturer')
      .order('created_at', { ascending: false })
      .limit(5)
    
    console.log('ğŸ“‹ ìµœê·¼ ì‘ì—… ê¸°ë¡ 5ê°œ:')
    recentRecords?.forEach((record, index) => {
      console.log(`  ${index + 1}. ID: ${record.id}, ë‚ ì§œ: ${record.work_date}, ECU: ${record.ecu_maker || 'N/A'}, ACU: ${record.acu_manufacturer || 'N/A'}`)
    })
    
  } catch (error) {
    console.error('âŒ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½ ì˜¤ë¥˜:', error)
  }
} 